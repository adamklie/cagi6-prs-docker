General:
    batchSize: 256
    optimizer: Adam
    learningRate: 0.0001 #5e-3
    epochs: 50
    hyperOptimize: True  #Add in hyperoptimized numTrials
    maxLayers: 8
    patience: 5
    activationFunction: LeakyReLU
    pathForCSVSummary: /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/CSV_Output_Files/SingleTask/ClinicalInclusion/T2D
    singleModelName: CAGI_T2D_NoFilterBaseline+_AgeMatched_5e-4_Sex_And_Age
    modelCheckpointingPath: /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Models/SingleTask/ClinicalInclusion/T2D
    hyperOptimizeTrials: 75 #How many models want optuna to select
    hyperOptimizeJobs: 2 #How many models to run concurrently
    numWorkers: 4
    studyLocation: /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Studies/SingleTask/ClinicalInclusion/CAGI_T2D.pkl #Path and file name for Optuna Study 
    studyName: CAGI_T2D_NoFilterBaseline+_AgeMatched_5e-4_Sex_And_Age
    sqlPath: /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Studies/SQL_Intermediates/
    
#Need to add activations as a hyperparameter, will need to adjust model Framework --> Also need to add Swish as activation f(n)
Multitask-FFN:  
    numLayers: 7
    layerWidths: [6096, 5880, 5211, 1723, 1168, 513, 490]
    dropout: 0.8 #Change in the model so can be tuned on a layerwise basis 
    inputDimension: 6286 #Number of Snps --> 1882
    multiTaskOutputs: [1,4] #Drive is a 2 task problem for Cancer and Ethnicity
    weightedTask: {"PC":1, "Ethn":1} #how much want to weight the loss functions against one another --> baseline weight them equally
    lossFunctions: [nn.BCEWithLogitsLoss(),nn.CrossEntropyLoss()] #For when want to use weighted loss functions for cases of class imbalance --> ex w/ random values pass in weight=[0.25, 0.75]
    weightedLoss: False #Whether or not want to weight the loss f(x)s
    weights: {"PC":[0.25, 0.75], "Ethnicity":[0.3,0.3,0.2,0.2], "FH":[0.69, 0.31]} #How much to weight each class per loss function when weightedLoss above == True
    
Dataloader:
    SNP_Path: /input/MGB.t2d.zscored.feather
    TestIDs: /input/MGB.ids.txt
    PhenotypeFile: /input/MGB.t2d.tsv
    Disease: PHENOTYPE
    
#Run Command: python ClinicalTestPredictionsAndAUC.py --config_path /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Configs/SingleTask/TestSets/ClinicalInclusion/T2D.yaml --model_path /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Models/SingleTask/ClinicalInclusion/T2D/Optuna_Study_Trial_16_Epoch_17.pt

#Docker Run Command: python GilderoyLockhart.py --model_path /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Models/SingleTask/ClinicalInclusion/T2D/Optuna_Study_Trial_16_Epoch_17.pt --config_path /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/Configs/SingleTask/TestSets/ClinicalInclusion/T2D.yaml --out_path /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DeweyIsOutOfTheGAGI/OtherStuff/temp_files --disease T2D